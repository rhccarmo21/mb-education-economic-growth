{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e5b24-7597-4eeb-91c0-4c5661bfa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ notebooks/00_complete_analysis.ipynb\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# An√°lise Completa: Educa√ß√£o e Crescimento Econ√¥mico\n",
    "\n",
    "An√°lise em tempo real usando APIs diretas para investigar a rela√ß√£o entre educa√ß√£o e crescimento econ√¥mico.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# ==================== CONFIGURA√á√ÉO E IMPORTS ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# %%\n",
    "# ==================== CLASSE PRINCIPAL DE AN√ÅLISE ====================\n",
    "class EducationEconomicAnalysis:\n",
    "    def __init__(self):\n",
    "        self.raw_data = None\n",
    "        self.processed_data = None\n",
    "        self.results = {}\n",
    "        self.countries = ['BRA', 'USA', 'CHN', 'IND', 'DEU', 'FRA', 'GBR', 'JPN', 'ZAF', 'MEX']\n",
    "        \n",
    "    def fetch_worldbank_data(self, indicator, countries):\n",
    "        \"\"\"Busca dados diretamente da API do Banco Mundial\"\"\"\n",
    "        url = f\"http://api.worldbank.org/v2/country/{';'.join(countries)}/indicator/{indicator}?format=json&per_page=10000\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if len(data) > 1:\n",
    "                    return [\n",
    "                        {\n",
    "                            'country': item['country']['id'],\n",
    "                            'country_name': item['country']['value'],\n",
    "                            'indicator': indicator,\n",
    "                            'year': int(item['date']),\n",
    "                            'value': float(item['value']) if item['value'] else None\n",
    "                        }\n",
    "                        for item in data[1] if item['value'] is not None\n",
    "                    ]\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao buscar {indicator}: {e}\")\n",
    "        return []\n",
    "\n",
    "    def collect_all_data(self):\n",
    "        \"\"\"Coleta dados de todos os indicadores em paralelo\"\"\"\n",
    "        indicators = {\n",
    "            'education': [\n",
    "                'SE.SEC.ENRR',      # Taxa de matr√≠cula secund√°ria\n",
    "                'SE.XPD.TOTL.GD.ZS', # Gasto em educa√ß√£o (% PIB)\n",
    "                'SE.TER.ENRR',      # Taxa de matr√≠cula terci√°ria\n",
    "                'SE.ADT.LITR.ZS',   # Taxa de alfabetiza√ß√£o\n",
    "            ],\n",
    "            'economic': [\n",
    "                'NY.GDP.PCAP.CD',   # PIB per capita\n",
    "                'NY.GDP.MKTP.KD.ZG', # Crescimento do PIB\n",
    "                'SL.UEM.TOTL.ZS',   # Taxa de desemprego\n",
    "                'NE.EXP.GNFS.ZS',   # Exporta√ß√µes (% PIB)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        all_data = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures = []\n",
    "            for category, ind_list in indicators.items():\n",
    "                for indicator in ind_list:\n",
    "                    futures.append(executor.submit(self.fetch_worldbank_data, indicator, self.countries))\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    all_data.extend(result)\n",
    "        \n",
    "        self.raw_data = pd.DataFrame(all_data)\n",
    "        return self.raw_data\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocessa e transforma os dados\"\"\"\n",
    "        if self.raw_data is None:\n",
    "            self.collect_all_data()\n",
    "        \n",
    "        # Converter para formato wide\n",
    "        wide_data = self.raw_data.pivot_table(\n",
    "            index=['country', 'country_name', 'year'],\n",
    "            columns='indicator',\n",
    "            values='value'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Remover anos com muitos missing values\n",
    "        wide_data = wide_data.dropna(thresh=8)\n",
    "        \n",
    "        # Engenharia de features\n",
    "        wide_data['edu_investment_ratio'] = wide_data['SE.XPD.TOTL.GD.ZS'] / wide_data['NY.GDP.PCAP.CD'].clip(lower=100)\n",
    "        wide_data['enrollment_ratio'] = wide_data['SE.TER.ENRR'] / wide_data['SE.SEC.ENRR'].clip(lower=1)\n",
    "        \n",
    "        # Calcular crescimento anual\n",
    "        wide_data = wide_data.sort_values(['country', 'year'])\n",
    "        for col in ['NY.GDP.PCAP.CD', 'SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']:\n",
    "            wide_data[f'{col}_growth'] = wide_data.groupby('country')[col].pct_change()\n",
    "        \n",
    "        self.processed_data = wide_data\n",
    "        return self.processed_data\n",
    "\n",
    "    def perform_statistical_analysis(self):\n",
    "        \"\"\"Realiza an√°lise estat√≠stica completa\"\"\"\n",
    "        if self.processed_data is None:\n",
    "            self.preprocess_data()\n",
    "        \n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        # 1. Correla√ß√µes\n",
    "        corr_matrix = df[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS', 'NY.GDP.PCAP.CD', \n",
    "                         'NY.GDP.MKTP.KD.ZG', 'edu_investment_ratio']].corr()\n",
    "        \n",
    "        # 2. Regress√£o linear\n",
    "        X = df[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']]\n",
    "        X = sm.add_constant(X)\n",
    "        y = df['NY.GDP.PCAP.CD']\n",
    "        \n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # 3. An√°lise por pa√≠s\n",
    "        country_correlations = {}\n",
    "        for country in df['country'].unique():\n",
    "            country_data = df[df['country'] == country]\n",
    "            if len(country_data) > 5:\n",
    "                corr = country_data['SE.SEC.ENRR'].corr(country_data['NY.GDP.PCAP.CD'])\n",
    "                country_correlations[country] = corr\n",
    "        \n",
    "        self.results = {\n",
    "            'correlation_matrix': corr_matrix,\n",
    "            'regression_model': model,\n",
    "            'country_correlations': country_correlations,\n",
    "            'summary_stats': df.describe()\n",
    "        }\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def clustering_analysis(self):\n",
    "        \"\"\"An√°lise de clusters de pa√≠ses\"\"\"\n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        # Dados m√©dios por pa√≠s\n",
    "        country_means = df.groupby('country').agg({\n",
    "            'SE.SEC.ENRR': 'mean',\n",
    "            'NY.GDP.PCAP.CD': 'mean',\n",
    "            'SE.XPD.TOTL.GD.ZS': 'mean',\n",
    "            'edu_investment_ratio': 'mean'\n",
    "        }).dropna()\n",
    "        \n",
    "        # Normalizar dados\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(country_means)\n",
    "        \n",
    "        # K-means clustering\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(scaled_data)\n",
    "        \n",
    "        country_means['cluster'] = clusters\n",
    "        \n",
    "        # PCA para visualiza√ß√£o\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        self.results['clustering'] = {\n",
    "            'country_means': country_means,\n",
    "            'pca_result': pca_result,\n",
    "            'explained_variance': pca.explained_variance_ratio_\n",
    "        }\n",
    "        \n",
    "        return country_means\n",
    "\n",
    "    def time_series_analysis(self):\n",
    "        \"\"\"An√°lise de s√©ries temporais\"\"\"\n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        # Calcular elasticidades ao longo do tempo\n",
    "        elasticities = {}\n",
    "        years = sorted(df['year'].unique())\n",
    "        \n",
    "        for year in years:\n",
    "            year_data = df[df['year'] == year]\n",
    "            if len(year_data) > 5:\n",
    "                try:\n",
    "                    # Regress√£o cross-section para cada ano\n",
    "                    X = year_data[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']]\n",
    "                    X = sm.add_constant(X)\n",
    "                    y = year_data['NY.GDP.PCAP.CD']\n",
    "                    \n",
    "                    model = sm.OLS(y, X).fit()\n",
    "                    elasticities[year] = {\n",
    "                        'enrollment_coef': model.params['SE.SEC.ENRR'],\n",
    "                        'spending_coef': model.params['SE.XPD.TOTL.GD.ZS'],\n",
    "                        'r_squared': model.rsquared\n",
    "                    }\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        self.results['time_series'] = elasticities\n",
    "        return elasticities\n",
    "\n",
    "    def create_visualizations(self):\n",
    "        \"\"\"Cria todas as visualiza√ß√µes\"\"\"\n",
    "        if self.processed_data is None:\n",
    "            self.preprocess_data()\n",
    "        \n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "        \n",
    "        # 1. Gr√°fico de dispers√£o principal\n",
    "        for country in df['country'].unique():\n",
    "            country_data = df[df['country'] == country]\n",
    "            axes[0, 0].scatter(country_data['SE.SEC.ENRR'], country_data['NY.GDP.PCAP.CD'],\n",
    "                              alpha=0.6, label=country, s=50)\n",
    "        axes[0, 0].set_xlabel('Taxa de Matr√≠cula Secund√°ria (%)')\n",
    "        axes[0, 0].set_ylabel('PIB per Capita (USD)')\n",
    "        axes[0, 0].set_title('Rela√ß√£o entre Educa√ß√£o e PIB per Capita')\n",
    "        axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # 2. Evolu√ß√£o temporal\n",
    "        for country in ['BRA', 'USA', 'CHN', 'IND']:\n",
    "            country_data = df[df['country'] == country]\n",
    "            if not country_data.empty:\n",
    "                axes[0, 1].plot(country_data['year'], country_data['SE.SEC.ENRR'],\n",
    "                               label=country, linewidth=2)\n",
    "        axes[0, 1].set_title('Evolu√ß√£o da Taxa de Matr√≠cula Secund√°ria')\n",
    "        axes[0, 1].set_xlabel('Ano')\n",
    "        axes[0, 1].set_ylabel('Taxa de Matr√≠cula (%)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Correla√ß√µes por pa√≠s\n",
    "        correlations = self.results.get('country_correlations', {})\n",
    "        if correlations:\n",
    "            axes[1, 0].bar(correlations.keys(), correlations.values())\n",
    "            axes[1, 0].set_title('Correla√ß√£o Educa√ß√£o-PIB por Pa√≠s')\n",
    "            axes[1, 0].set_ylabel('Coeficiente de Correla√ß√£o')\n",
    "            axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 4. Heatmap de correla√ß√µes\n",
    "        corr_matrix = self.results.get('correlation_matrix', pd.DataFrame())\n",
    "        if not corr_matrix.empty:\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                       ax=axes[1, 1])\n",
    "            axes[1, 1].set_title('Matriz de Correla√ß√£o')\n",
    "        \n",
    "        # 5. An√°lise de clusters\n",
    "        clustering = self.results.get('clustering', {})\n",
    "        if clustering:\n",
    "            pca_result = clustering['pca_result']\n",
    "            country_means = clustering['country_means']\n",
    "            scatter = axes[2, 0].scatter(pca_result[:, 0], pca_result[:, 1],\n",
    "                                       c=country_means['cluster'], cmap='viridis', s=100)\n",
    "            for i, country in enumerate(country_means.index):\n",
    "                axes[2, 0].annotate(country, (pca_result[i, 0], pca_result[i, 1]),\n",
    "                                   xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "            axes[2, 0].set_title('An√°lise de Clusters de Pa√≠ses')\n",
    "            axes[2, 0].set_xlabel(f'PC1 ({clustering[\"explained_variance\"][0]:.1%} var.)')\n",
    "            axes[2, 0].set_ylabel(f'PC2 ({clustering[\"explained_variance\"][1]:.1%} var.)')\n",
    "        \n",
    "        # 6. Elasticidades ao longo do tempo\n",
    "        time_series = self.results.get('time_series', {})\n",
    "        if time_series:\n",
    "            years = list(time_series.keys())\n",
    "            enrollment_coefs = [time_series[year]['enrollment_coef'] for year in years]\n",
    "            axes[2, 1].plot(years, enrollment_coefs, marker='o', linewidth=2)\n",
    "            axes[2, 1].set_title('Elasticidade Educa√ß√£o-PIB ao Longo do Tempo')\n",
    "            axes[2, 1].set_xlabel('Ano')\n",
    "            axes[2, 1].set_ylabel('Coeficiente de Elasticidade')\n",
    "            axes[2, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('complete_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_to_serializable(self, obj):\n",
    "        \"\"\"Converte objetos numpy/pandas para tipos serializ√°veis JSON\"\"\"\n",
    "        if isinstance(obj, (np.integer, np.int64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, pd.DataFrame):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, pd.Series):\n",
    "            return obj.to_dict()\n",
    "        elif hasattr(obj, 'to_json'):\n",
    "            return obj.to_json()\n",
    "        elif hasattr(obj, '__dict__'):\n",
    "            return {k: self._convert_to_serializable(v) for k, v in obj.__dict__.items()}\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Gera relat√≥rio completo da an√°lise\"\"\"\n",
    "        if not self.results:\n",
    "            self.perform_statistical_analysis()\n",
    "            self.clustering_analysis()\n",
    "            self.time_series_analysis()\n",
    "        \n",
    "        # Converter todos os valores para tipos serializ√°veis\n",
    "        report = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'countries_analyzed': self.countries,\n",
    "            'data_points': len(self.processed_data) if self.processed_data is not None else 0,\n",
    "            'time_period': {\n",
    "                'start': int(self.processed_data['year'].min()) if self.processed_data is not None else None,\n",
    "                'end': int(self.processed_data['year'].max()) if self.processed_data is not None else None\n",
    "            },\n",
    "            'correlation_summary': {\n",
    "                'education_gdp': float(self.results['correlation_matrix'].loc['SE.SEC.ENRR', 'NY.GDP.PCAP.CD']),\n",
    "                'spending_gdp': float(self.results['correlation_matrix'].loc['SE.XPD.TOTL.GD.ZS', 'NY.GDP.PCAP.CD'])\n",
    "            },\n",
    "            'regression_results': {\n",
    "                'rsquared': float(self.results['regression_model'].rsquared),\n",
    "                'params': {k: float(v) for k, v in self.results['regression_model'].params.items()},\n",
    "                'pvalues': {k: float(v) for k, v in self.results['regression_model'].pvalues.items()}\n",
    "            },\n",
    "            'country_correlations': {k: float(v) for k, v in self.results['country_correlations'].items()}\n",
    "        }\n",
    "        \n",
    "        # Adicionar clustering se dispon√≠vel\n",
    "        if 'clustering' in self.results:\n",
    "            report['clustering_summary'] = {\n",
    "                'n_clusters': int(self.results['clustering']['country_means']['cluster'].nunique()),\n",
    "                'cluster_sizes': self.results['clustering']['country_means']['cluster'].value_counts().to_dict()\n",
    "            }\n",
    "        \n",
    "        # Adicionar time series se dispon√≠vel\n",
    "        if 'time_series' in self.results:\n",
    "            report['time_series_summary'] = {\n",
    "                'years_analyzed': len(self.results['time_series']),\n",
    "                'avg_enrollment_coef': float(np.mean([v['enrollment_coef'] for v in self.results['time_series'].values()])),\n",
    "                'avg_r_squared': float(np.mean([v['r_squared'] for v in self.results['time_series'].values()]))\n",
    "            }\n",
    "        \n",
    "        # Salvar relat√≥rio\n",
    "        with open('analysis_report.json', 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        return report\n",
    "\n",
    "# %%\n",
    "# ==================== EXECU√á√ÉO DA AN√ÅLISE COMPLETA ====================\n",
    "\n",
    "# Instanciar e executar an√°lise\n",
    "print(\"üöÄ Iniciando an√°lise completa...\")\n",
    "analyzer = EducationEconomicAnalysis()\n",
    "\n",
    "print(\"üìä Coletando dados das APIs...\")\n",
    "raw_data = analyzer.collect_all_data()\n",
    "print(f\"‚úÖ Dados coletados: {len(raw_data)} registros\")\n",
    "\n",
    "print(\"üîß Processando dados...\")\n",
    "processed_data = analyzer.preprocess_data()\n",
    "print(f\"‚úÖ Dados processados: {processed_data.shape}\")\n",
    "\n",
    "print(\"üìà Realizando an√°lise estat√≠stica...\")\n",
    "results = analyzer.perform_statistical_analysis()\n",
    "print(\"‚úÖ An√°lise estat√≠stica conclu√≠da\")\n",
    "\n",
    "print(\"üë• Executando an√°lise de clusters...\")\n",
    "clusters = analyzer.clustering_analysis()\n",
    "print(\"‚úÖ An√°lise de clusters conclu√≠da\")\n",
    "\n",
    "print(\"‚è∞ Realizando an√°lise de s√©ries temporais...\")\n",
    "time_series = analyzer.time_series_analysis()\n",
    "print(\"‚úÖ An√°lise temporal conclu√≠da\")\n",
    "\n",
    "print(\"üé® Gerando visualiza√ß√µes...\")\n",
    "analyzer.create_visualizations()\n",
    "print(\"‚úÖ Visualiza√ß√µes salvas\")\n",
    "\n",
    "print(\"üìã Gerando relat√≥rio final...\")\n",
    "report = analyzer.generate_report()\n",
    "print(\"‚úÖ Relat√≥rio gerado\")\n",
    "\n",
    "# %%\n",
    "# ==================== RESULTADOS E INSIGHTS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESULTADOS PRINCIPAIS DA AN√ÅLISE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Correla√ß√£o educa√ß√£o-PIB\n",
    "corr_edu_gdp = report['correlation_summary']['education_gdp']\n",
    "print(f\"üìà Correla√ß√£o Educa√ß√£o-PIB: {corr_edu_gdp:.3f}\")\n",
    "\n",
    "# Resultados da regress√£o\n",
    "rsquared = report['regression_results']['rsquared']\n",
    "edu_coef = report['regression_results']['params']['SE.SEC.ENRR']\n",
    "edu_pvalue = report['regression_results']['pvalues']['SE.SEC.ENRR']\n",
    "\n",
    "print(f\"üîç R¬≤ do modelo: {rsquared:.3f}\")\n",
    "print(f\"üìö Coeficiente Educa√ß√£o: {edu_coef:.3f} (p-value: {edu_pvalue:.4f})\")\n",
    "\n",
    "# An√°lise de clusters\n",
    "if 'clustering_summary' in report:\n",
    "    print(f\"üë• Pa√≠ses agrupados em {report['clustering_summary']['n_clusters']} clusters\")\n",
    "    for cluster, count in report['clustering_summary']['cluster_sizes'].items():\n",
    "        print(f\"   Cluster {cluster}: {count} pa√≠ses\")\n",
    "\n",
    "# An√°lise por pa√≠s\n",
    "print(\"\\nüáßüá∑ An√°lise espec√≠fica do Brasil:\")\n",
    "brazil_data = analyzer.processed_data[analyzer.processed_data['country'] == 'BRA'].dropna()\n",
    "if not brazil_data.empty:\n",
    "    latest_year = brazil_data['year'].max()\n",
    "    latest_data = brazil_data[brazil_data['year'] == latest_year].iloc[0]\n",
    "    \n",
    "    print(f\"   Ano mais recente: {int(latest_year)}\")\n",
    "    print(f\"   PIB per capita: USD {float(latest_data['NY.GDP.PCAP.CD']):,.0f}\")\n",
    "    print(f\"   Matr√≠cula secund√°ria: {float(latest_data['SE.SEC.ENRR']):.1f}%\")\n",
    "    print(f\"   Gasto em educa√ß√£o: {float(latest_data['SE.XPD.TOTL.GD.ZS']):.1f}% do PIB\")\n",
    "\n",
    "# %%\n",
    "# ==================== AN√ÅLISE COMPARATIVA ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üåç AN√ÅLISE COMPARATIVA ENTRE PA√çSES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Primeiro, vamos verificar quais colunas est√£o dispon√≠veis\n",
    "print(\"Colunas dispon√≠veis no processed_data:\")\n",
    "print(analyzer.processed_data.columns.tolist())\n",
    "\n",
    "# Dados mais recentes por pa√≠s - usando os nomes corretos das colunas\n",
    "latest_data = []\n",
    "for country in analyzer.countries:\n",
    "    country_data = analyzer.processed_data[analyzer.processed_data['country'] == country].dropna()\n",
    "    if not country_data.empty:\n",
    "        latest_year = country_data['year'].max()\n",
    "        latest_row = country_data[country_data['year'] == latest_year].iloc[0]\n",
    "        \n",
    "        # Usar os nomes corretos das colunas do World Bank\n",
    "        latest_data.append({\n",
    "            'country': country,\n",
    "            'year': int(latest_year),\n",
    "            'NY.GDP.PCAP.CD': float(latest_row['NY.GDP.PCAP.CD']) if 'NY.GDP.PCAP.CD' in latest_row else None,\n",
    "            'SE.SEC.ENRR': float(latest_row['SE.SEC.ENRR']) if 'SE.SEC.ENRR' in latest_row else None,\n",
    "            'SE.XPD.TOTL.GD.ZS': float(latest_row['SE.XPD.TOTL.GD.ZS']) if 'SE.XPD.TOTL.GD.ZS' in latest_row else None\n",
    "        })\n",
    "\n",
    "latest_df = pd.DataFrame(latest_data)\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "latest_df = latest_df.dropna()\n",
    "\n",
    "# Top pa√≠ses em diferentes m√©tricas - usando os nomes corretos das colunas\n",
    "if not latest_df.empty and 'NY.GDP.PCAP.CD' in latest_df.columns:\n",
    "    print(\"\\nüèÜ Top 5 pa√≠ses por PIB per capita:\")\n",
    "    top_gdp = latest_df.nlargest(5, 'NY.GDP.PCAP.CD')[['country', 'NY.GDP.PCAP.CD']].copy()\n",
    "    top_gdp['NY.GDP.PCAP.CD'] = top_gdp['NY.GDP.PCAP.CD'].apply(lambda x: f\"USD {x:,.0f}\")\n",
    "    print(top_gdp.to_string(index=False))\n",
    "\n",
    "if not latest_df.empty and 'SE.SEC.ENRR' in latest_df.columns:\n",
    "    print(\"\\nüéì Top 5 pa√≠ses por matr√≠cula secund√°ria:\")\n",
    "    top_edu = latest_df.nlargest(5, 'SE.SEC.ENRR')[['country', 'SE.SEC.ENRR']].copy()\n",
    "    top_edu['SE.SEC.ENRR'] = top_edu['SE.SEC.ENRR'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    print(top_edu.to_string(index=False))\n",
    "\n",
    "if not latest_df.empty and 'SE.XPD.TOTL.GD.ZS' in latest_df.columns:\n",
    "    print(\"\\nüí∞ Top 5 pa√≠ses por gasto em educa√ß√£o (% PIB):\")\n",
    "    top_spend = latest_df.nlargest(5, 'SE.XPD.TOTL.GD.ZS')[['country', 'SE.XPD.TOTL.GD.ZS']].copy()\n",
    "    top_spend['SE.XPD.TOTL.GD.ZS'] = top_spend['SE.XPD.TOTL.GD.ZS'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    print(top_spend.to_string(index=False))\n",
    "\n",
    "# %%\n",
    "# ==================== TESTES ESTAT√çSTICOS AVAN√áADOS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TESTES ESTAT√çSTICOS AVAN√áADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se temos dados suficientes para an√°lise\n",
    "if not latest_df.empty and 'NY.GDP.PCAP.CD' in latest_df.columns and 'SE.SEC.ENRR' in latest_df.columns:\n",
    "    \n",
    "    # Teste de diferen√ßas entre grupos de renda\n",
    "    # Classificar pa√≠ses por renda\n",
    "    latest_df['income_group'] = pd.qcut(latest_df['NY.GDP.PCAP.CD'], 3, labels=['Baixa', 'M√©dia', 'Alta'])\n",
    "    \n",
    "    # ANOVA para diferen√ßas na matr√≠cula entre grupos de renda\n",
    "    groups = []\n",
    "    for group in ['Baixa', 'M√©dia', 'Alta']:\n",
    "        group_data = latest_df[latest_df['income_group'] == group]['SE.SEC.ENRR'].dropna()\n",
    "        if len(group_data) > 0:\n",
    "            groups.append(group_data)\n",
    "    \n",
    "    if len(groups) >= 2:\n",
    "        f_stat, p_value = stats.f_oneway(*groups)\n",
    "        print(f\"üìä ANOVA - Diferen√ßas na matr√≠cula por grupo de renda:\")\n",
    "        print(f\"   F-statistic: {f_stat:.3f}, p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Correla√ß√£o e teste de signific√¢ncia\n",
    "    corr_test = stats.pearsonr(latest_df['SE.SEC.ENRR'], latest_df['NY.GDP.PCAP.CD'])\n",
    "    print(f\"üîç Correla√ß√£o Educa√ß√£o-PIB: {corr_test.statistic:.3f}\")\n",
    "    print(f\"üìã Teste de signific√¢ncia da correla√ß√£o:\")\n",
    "    print(f\"   p-value: {corr_test.pvalue:.4f}\")\n",
    "    \n",
    "    # Correla√ß√£o parcial (controlando por gastos em educa√ß√£o)\n",
    "    if 'SE.XPD.TOTL.GD.ZS' in latest_df.columns:\n",
    "        # Usar regress√£o linear para correla√ß√£o parcial\n",
    "        X = latest_df[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']].dropna()\n",
    "        y = latest_df['NY.GDP.PCAP.CD'].loc[X.index]\n",
    "        \n",
    "        if len(X) > 5:\n",
    "            X = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            partial_corr = model.params['SE.SEC.ENRR']\n",
    "            print(f\"üìà Coeficiente parcial Educa√ß√£o-PIB (controlando gastos): {partial_corr:.3f}\")\n",
    "\n",
    "# %%\n",
    "# ==================== SALVANDO RESULTADOS COMPLETOS ====================\n",
    "\n",
    "# Salvar dados processados\n",
    "analyzer.processed_data.to_csv('processed_education_economic_data.csv', index=False)\n",
    "\n",
    "# Salvar resultados estat√≠sticos detalhados\n",
    "statistical_results = {\n",
    "    'correlation_matrix': analyzer.results['correlation_matrix'].to_dict(),\n",
    "    'regression_summary': {\n",
    "        'rsquared': float(analyzer.results['regression_model'].rsquared),\n",
    "        'rsquared_adj': float(analyzer.results['regression_model'].rsquared_adj),\n",
    "        'f_statistic': float(analyzer.results['regression_model'].fvalue),\n",
    "        'f_pvalue': float(analyzer.results['regression_model'].f_pvalue),\n",
    "        'params': {k: float(v) for k, v in analyzer.results['regression_model'].params.items()},\n",
    "        'pvalues': {k: float(v) for k, v in analyzer.results['regression_model'].pvalues.items()}\n",
    "    },\n",
    "    'country_correlations': {k: float(v) for k, v in analyzer.results['country_correlations'].items()}\n",
    "}\n",
    "\n",
    "with open('statistical_results.json', 'w') as f:\n",
    "    json.dump(statistical_results, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise completa conclu√≠da!\")\n",
    "print(\"üìÅ Arquivos salvos:\")\n",
    "print(\"   - processed_education_economic_data.csv\")\n",
    "print(\"   - statistical_results.json\")\n",
    "print(\"   - analysis_report.json\")\n",
    "print(\"   - complete_analysis.png\")\n",
    "\n",
    "# %%\n",
    "# ==================== INSIGHTS FINAIS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° INSIGHTS E RECOMENDA√á√ïES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Insights baseados nos resultados\n",
    "if corr_edu_gdp > 0.5:\n",
    "    print(\"üéØ Insight 1: Forte correla√ß√£o positiva entre educa√ß√£o e crescimento econ√¥mico\")\n",
    "    print(\"   ‚Üí Investimentos em educa√ß√£o t√™m impacto significativo no PIB\")\n",
    "elif corr_edu_gdp > 0.3:\n",
    "    print(\"üéØ Insight 1: Correla√ß√£o moderada entre educa√ß√£o e crescimento econ√¥mico\")\n",
    "    print(\"   ‚Üí Educa√ß√£o √© um dos fatores importantes para o desenvolvimento\")\n",
    "else:\n",
    "    print(\"üéØ Insight 1: Correla√ß√£o fraca entre educa√ß√£o e crescimento econ√¥mico\")\n",
    "    print(\"   ‚Üí Outros fatores podem ter maior impacto no crescimento\")\n",
    "\n",
    "if edu_pvalue < 0.05:\n",
    "    print(\"üéØ Insight 2: Rela√ß√£o estatisticamente significativa (p < 0.05)\")\n",
    "    print(\"   ‚Üí Os resultados n√£o s√£o devidos ao acaso\")\n",
    "else:\n",
    "    print(\"üéØ Insight 2: Rela√ß√£o n√£o estatisticamente significativa\")\n",
    "    print(\"   ‚Üí Resultados podem ser devido a varia√ß√£o aleat√≥ria\")\n",
    "\n",
    "# Recomenda√ß√µes baseadas nos clusters\n",
    "if 'clustering_summary' in report:\n",
    "    cluster_sizes = report['clustering_summary']['cluster_sizes']\n",
    "    if len(cluster_sizes) > 1:\n",
    "        print(\"üéØ Insight 3: Pa√≠ses se agrupam em perfis distintos de desenvolvimento\")\n",
    "        print(\"   ‚Üí Pol√≠ticas educacionais devem ser adaptadas a cada perfil\")\n",
    "\n",
    "print(\"\\nüìã Recomenda√ß√µes para pol√≠ticas p√∫blicas:\")\n",
    "print(\"   1. Aumentar investimentos em educa√ß√£o secund√°ria e terci√°ria\")\n",
    "print(\"   2. Focar na qualidade do ensino al√©m da quantidade de matr√≠culas\")\n",
    "print(\"   3. Desenvolver pol√≠ticas espec√≠ficas para cada grupo de pa√≠ses\")\n",
    "print(\"   4. Monitorar continuamente a rela√ß√£o educa√ß√£o-crescimento\")\n",
    "\n",
    "print(\"\\nüîÆ Pr√≥ximos passos para pesquisa:\")\n",
    "print(\"   1. Investigar causalidade (educa√ß√£o ‚Üí crescimento ou crescimento ‚Üí educa√ß√£o?)\")\n",
    "print(\"   2. Analisar o papel de vari√°veis intermedi√°rias (tecnologia, inova√ß√£o)\")\n",
    "print(\"   3. Estudo longitudinal de pa√≠ses espec√≠ficos\")\n",
    "print(\"   4. An√°lise de pol√≠ticas educacionais bem-sucedidas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
