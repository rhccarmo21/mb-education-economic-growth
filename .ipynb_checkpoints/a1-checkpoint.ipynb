{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e5b24-7597-4eeb-91c0-4c5661bfa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ notebooks/00_complete_analysis.ipynb\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# AnÃ¡lise Completa: EducaÃ§Ã£o e Crescimento EconÃ´mico\n",
    "\n",
    "AnÃ¡lise em tempo real usando APIs diretas para investigar a relaÃ§Ã£o entre educaÃ§Ã£o e crescimento econÃ´mico.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# ==================== CONFIGURAÃ‡ÃƒO E IMPORTS ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraÃ§Ã£o de visualizaÃ§Ã£o\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# %%\n",
    "# ==================== CLASSE PRINCIPAL DE ANÃLISE ====================\n",
    "class EducationEconomicAnalysis:\n",
    "    def __init__(self):\n",
    "        self.raw_data = None\n",
    "        self.processed_data = None\n",
    "        self.results = {}\n",
    "        self.countries = ['BRA', 'USA', 'CHN', 'IND', 'DEU', 'FRA', 'GBR', 'JPN', 'ZAF', 'MEX']\n",
    "        \n",
    "    def fetch_worldbank_data(self, indicator, countries):\n",
    "        \"\"\"Busca dados diretamente da API do Banco Mundial\"\"\"\n",
    "        url = f\"http://api.worldbank.org/v2/country/{';'.join(countries)}/indicator/{indicator}?format=json&per_page=10000\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if len(data) > 1:\n",
    "                    return [\n",
    "                        {\n",
    "                            'country': item['country']['id'],\n",
    "                            'country_name': item['country']['value'],\n",
    "                            'indicator': indicator,\n",
    "                            'year': int(item['date']),\n",
    "                            'value': float(item['value']) if item['value'] else None\n",
    "                        }\n",
    "                        for item in data[1] if item['value'] is not None\n",
    "                    ]\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao buscar {indicator}: {e}\")\n",
    "        return []\n",
    "\n",
    "    def collect_all_data(self):\n",
    "        \"\"\"Coleta dados de todos os indicadores em paralelo\"\"\"\n",
    "        indicators = {\n",
    "            'education': [\n",
    "                'SE.SEC.ENRR',      # Taxa de matrÃ­cula secundÃ¡ria\n",
    "                'SE.XPD.TOTL.GD.ZS', # Gasto em educaÃ§Ã£o (% PIB)\n",
    "                'SE.TER.ENRR',      # Taxa de matrÃ­cula terciÃ¡ria\n",
    "                'SE.ADT.LITR.ZS',   # Taxa de alfabetizaÃ§Ã£o\n",
    "            ],\n",
    "            'economic': [\n",
    "                'NY.GDP.PCAP.CD',   # PIB per capita\n",
    "                'NY.GDP.MKTP.KD.ZG', # Crescimento do PIB\n",
    "                'SL.UEM.TOTL.ZS',   # Taxa de desemprego\n",
    "                'NE.EXP.GNFS.ZS',   # ExportaÃ§Ãµes (% PIB)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        all_data = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures = []\n",
    "            for category, ind_list in indicators.items():\n",
    "                for indicator in ind_list:\n",
    "                    futures.append(executor.submit(self.fetch_worldbank_data, indicator, self.countries))\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    all_data.extend(result)\n",
    "        \n",
    "        self.raw_data = pd.DataFrame(all_data)\n",
    "        return self.raw_data\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocessa e transforma os dados\"\"\"\n",
    "        if self.raw_data is None:\n",
    "            self.collect_all_data()\n",
    "        \n",
    "        # Converter para formato wide\n",
    "        wide_data = self.raw_data.pivot_table(\n",
    "            index=['country', 'country_name', 'year'],\n",
    "            columns='indicator',\n",
    "            values='value'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Remover anos com muitos missing values\n",
    "        wide_data = wide_data.dropna(thresh=8)\n",
    "        \n",
    "        # Engenharia de features\n",
    "        wide_data['edu_investment_ratio'] = wide_data['SE.XPD.TOTL.GD.ZS'] / wide_data['NY.GDP.PCAP.CD'].clip(lower=100)\n",
    "        wide_data['enrollment_ratio'] = wide_data['SE.TER.ENRR'] / wide_data['SE.SEC.ENRR'].clip(lower=1)\n",
    "        \n",
    "        # Calcular crescimento anual\n",
    "        wide_data = wide_data.sort_values(['country', 'year'])\n",
    "        for col in ['NY.GDP.PCAP.CD', 'SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']:\n",
    "            wide_data[f'{col}_growth'] = wide_data.groupby('country')[col].pct_change()\n",
    "        \n",
    "        self.processed_data = wide_data\n",
    "        return self.processed_data\n",
    "\n",
    "    def perform_statistical_analysis(self):\n",
    "        \"\"\"Realiza anÃ¡lise estatÃ­stica completa\"\"\"\n",
    "        if self.processed_data is None:\n",
    "            self.preprocess_data()\n",
    "        \n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        # 1. CorrelaÃ§Ãµes\n",
    "        corr_matrix = df[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS', 'NY.GDP.PCAP.CD', \n",
    "                         'NY.GDP.MKTP.KD.ZG', 'edu_investment_ratio']].corr()\n",
    "        \n",
    "        # 2. RegressÃ£o linear\n",
    "        X = df[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']]\n",
    "        X = sm.add_constant(X)\n",
    "        y = df['NY.GDP.PCAP.CD']\n",
    "        \n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # 3. AnÃ¡lise por paÃ­s\n",
    "        country_correlations = {}\n",
    "        for country in df['country'].unique():\n",
    "            country_data = df[df['country'] == country]\n",
    "            if len(country_data) > 5:\n",
    "                corr = country_data['SE.SEC.ENRR'].corr(country_data['NY.GDP.PCAP.CD'])\n",
    "                country_correlations[country] = corr\n",
    "        \n",
    "        self.results = {\n",
    "            'correlation_matrix': corr_matrix,\n",
    "            'regression_model': model,\n",
    "            'country_correlations': country_correlations,\n",
    "            'summary_stats': df.describe()\n",
    "        }\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def clustering_analysis(self):\n",
    "        \"\"\"AnÃ¡lise de clusters de paÃ­ses\"\"\"\n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        # Dados mÃ©dios por paÃ­s\n",
    "        country_means = df.groupby('country').agg({\n",
    "            'SE.SEC.ENRR': 'mean',\n",
    "            'NY.GDP.PCAP.CD': 'mean',\n",
    "            'SE.XPD.TOTL.GD.ZS': 'mean',\n",
    "            'edu_investment_ratio': 'mean'\n",
    "        }).dropna()\n",
    "        \n",
    "        # Normalizar dados\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(country_means)\n",
    "        \n",
    "        # K-means clustering\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(scaled_data)\n",
    "        \n",
    "        country_means['cluster'] = clusters\n",
    "        \n",
    "        # PCA para visualizaÃ§Ã£o\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        self.results['clustering'] = {\n",
    "            'country_means': country_means,\n",
    "            'pca_result': pca_result,\n",
    "            'explained_variance': pca.explained_variance_ratio_\n",
    "        }\n",
    "        \n",
    "        return country_means\n",
    "\n",
    "    def time_series_analysis(self):\n",
    "        \"\"\"AnÃ¡lise de sÃ©ries temporais\"\"\"\n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        # Calcular elasticidades ao longo do tempo\n",
    "        elasticities = {}\n",
    "        years = sorted(df['year'].unique())\n",
    "        \n",
    "        for year in years:\n",
    "            year_data = df[df['year'] == year]\n",
    "            if len(year_data) > 5:\n",
    "                try:\n",
    "                    # RegressÃ£o cross-section para cada ano\n",
    "                    X = year_data[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']]\n",
    "                    X = sm.add_constant(X)\n",
    "                    y = year_data['NY.GDP.PCAP.CD']\n",
    "                    \n",
    "                    model = sm.OLS(y, X).fit()\n",
    "                    elasticities[year] = {\n",
    "                        'enrollment_coef': model.params['SE.SEC.ENRR'],\n",
    "                        'spending_coef': model.params['SE.XPD.TOTL.GD.ZS'],\n",
    "                        'r_squared': model.rsquared\n",
    "                    }\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        self.results['time_series'] = elasticities\n",
    "        return elasticities\n",
    "\n",
    "    def create_visualizations(self):\n",
    "        \"\"\"Cria todas as visualizaÃ§Ãµes\"\"\"\n",
    "        if self.processed_data is None:\n",
    "            self.preprocess_data()\n",
    "        \n",
    "        df = self.processed_data.dropna()\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "        \n",
    "        # 1. GrÃ¡fico de dispersÃ£o principal\n",
    "        for country in df['country'].unique():\n",
    "            country_data = df[df['country'] == country]\n",
    "            axes[0, 0].scatter(country_data['SE.SEC.ENRR'], country_data['NY.GDP.PCAP.CD'],\n",
    "                              alpha=0.6, label=country, s=50)\n",
    "        axes[0, 0].set_xlabel('Taxa de MatrÃ­cula SecundÃ¡ria (%)')\n",
    "        axes[0, 0].set_ylabel('PIB per Capita (USD)')\n",
    "        axes[0, 0].set_title('RelaÃ§Ã£o entre EducaÃ§Ã£o e PIB per Capita')\n",
    "        axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # 2. EvoluÃ§Ã£o temporal\n",
    "        for country in ['BRA', 'USA', 'CHN', 'IND']:\n",
    "            country_data = df[df['country'] == country]\n",
    "            if not country_data.empty:\n",
    "                axes[0, 1].plot(country_data['year'], country_data['SE.SEC.ENRR'],\n",
    "                               label=country, linewidth=2)\n",
    "        axes[0, 1].set_title('EvoluÃ§Ã£o da Taxa de MatrÃ­cula SecundÃ¡ria')\n",
    "        axes[0, 1].set_xlabel('Ano')\n",
    "        axes[0, 1].set_ylabel('Taxa de MatrÃ­cula (%)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. CorrelaÃ§Ãµes por paÃ­s\n",
    "        correlations = self.results.get('country_correlations', {})\n",
    "        if correlations:\n",
    "            axes[1, 0].bar(correlations.keys(), correlations.values())\n",
    "            axes[1, 0].set_title('CorrelaÃ§Ã£o EducaÃ§Ã£o-PIB por PaÃ­s')\n",
    "            axes[1, 0].set_ylabel('Coeficiente de CorrelaÃ§Ã£o')\n",
    "            axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 4. Heatmap de correlaÃ§Ãµes\n",
    "        corr_matrix = self.results.get('correlation_matrix', pd.DataFrame())\n",
    "        if not corr_matrix.empty:\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                       ax=axes[1, 1])\n",
    "            axes[1, 1].set_title('Matriz de CorrelaÃ§Ã£o')\n",
    "        \n",
    "        # 5. AnÃ¡lise de clusters\n",
    "        clustering = self.results.get('clustering', {})\n",
    "        if clustering:\n",
    "            pca_result = clustering['pca_result']\n",
    "            country_means = clustering['country_means']\n",
    "            scatter = axes[2, 0].scatter(pca_result[:, 0], pca_result[:, 1],\n",
    "                                       c=country_means['cluster'], cmap='viridis', s=100)\n",
    "            for i, country in enumerate(country_means.index):\n",
    "                axes[2, 0].annotate(country, (pca_result[i, 0], pca_result[i, 1]),\n",
    "                                   xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "            axes[2, 0].set_title('AnÃ¡lise de Clusters de PaÃ­ses')\n",
    "            axes[2, 0].set_xlabel(f'PC1 ({clustering[\"explained_variance\"][0]:.1%} var.)')\n",
    "            axes[2, 0].set_ylabel(f'PC2 ({clustering[\"explained_variance\"][1]:.1%} var.)')\n",
    "        \n",
    "        # 6. Elasticidades ao longo do tempo\n",
    "        time_series = self.results.get('time_series', {})\n",
    "        if time_series:\n",
    "            years = list(time_series.keys())\n",
    "            enrollment_coefs = [time_series[year]['enrollment_coef'] for year in years]\n",
    "            axes[2, 1].plot(years, enrollment_coefs, marker='o', linewidth=2)\n",
    "            axes[2, 1].set_title('Elasticidade EducaÃ§Ã£o-PIB ao Longo do Tempo')\n",
    "            axes[2, 1].set_xlabel('Ano')\n",
    "            axes[2, 1].set_ylabel('Coeficiente de Elasticidade')\n",
    "            axes[2, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('complete_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_to_serializable(self, obj):\n",
    "        \"\"\"Converte objetos numpy/pandas para tipos serializÃ¡veis JSON\"\"\"\n",
    "        if isinstance(obj, (np.integer, np.int64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, pd.DataFrame):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, pd.Series):\n",
    "            return obj.to_dict()\n",
    "        elif hasattr(obj, 'to_json'):\n",
    "            return obj.to_json()\n",
    "        elif hasattr(obj, '__dict__'):\n",
    "            return {k: self._convert_to_serializable(v) for k, v in obj.__dict__.items()}\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Gera relatÃ³rio completo da anÃ¡lise\"\"\"\n",
    "        if not self.results:\n",
    "            self.perform_statistical_analysis()\n",
    "            self.clustering_analysis()\n",
    "            self.time_series_analysis()\n",
    "        \n",
    "        # Converter todos os valores para tipos serializÃ¡veis\n",
    "        report = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'countries_analyzed': self.countries,\n",
    "            'data_points': len(self.processed_data) if self.processed_data is not None else 0,\n",
    "            'time_period': {\n",
    "                'start': int(self.processed_data['year'].min()) if self.processed_data is not None else None,\n",
    "                'end': int(self.processed_data['year'].max()) if self.processed_data is not None else None\n",
    "            },\n",
    "            'correlation_summary': {\n",
    "                'education_gdp': float(self.results['correlation_matrix'].loc['SE.SEC.ENRR', 'NY.GDP.PCAP.CD']),\n",
    "                'spending_gdp': float(self.results['correlation_matrix'].loc['SE.XPD.TOTL.GD.ZS', 'NY.GDP.PCAP.CD'])\n",
    "            },\n",
    "            'regression_results': {\n",
    "                'rsquared': float(self.results['regression_model'].rsquared),\n",
    "                'params': {k: float(v) for k, v in self.results['regression_model'].params.items()},\n",
    "                'pvalues': {k: float(v) for k, v in self.results['regression_model'].pvalues.items()}\n",
    "            },\n",
    "            'country_correlations': {k: float(v) for k, v in self.results['country_correlations'].items()}\n",
    "        }\n",
    "        \n",
    "        # Adicionar clustering se disponÃ­vel\n",
    "        if 'clustering' in self.results:\n",
    "            report['clustering_summary'] = {\n",
    "                'n_clusters': int(self.results['clustering']['country_means']['cluster'].nunique()),\n",
    "                'cluster_sizes': self.results['clustering']['country_means']['cluster'].value_counts().to_dict()\n",
    "            }\n",
    "        \n",
    "        # Adicionar time series se disponÃ­vel\n",
    "        if 'time_series' in self.results:\n",
    "            report['time_series_summary'] = {\n",
    "                'years_analyzed': len(self.results['time_series']),\n",
    "                'avg_enrollment_coef': float(np.mean([v['enrollment_coef'] for v in self.results['time_series'].values()])),\n",
    "                'avg_r_squared': float(np.mean([v['r_squared'] for v in self.results['time_series'].values()]))\n",
    "            }\n",
    "        \n",
    "        # Salvar relatÃ³rio\n",
    "        with open('analysis_report.json', 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        return report\n",
    "\n",
    "# %%\n",
    "# ==================== EXECUÃ‡ÃƒO DA ANÃLISE COMPLETA ====================\n",
    "\n",
    "# Instanciar e executar anÃ¡lise\n",
    "print(\"ğŸš€ Iniciando anÃ¡lise completa...\")\n",
    "analyzer = EducationEconomicAnalysis()\n",
    "\n",
    "print(\"ğŸ“Š Coletando dados das APIs...\")\n",
    "raw_data = analyzer.collect_all_data()\n",
    "print(f\"âœ… Dados coletados: {len(raw_data)} registros\")\n",
    "\n",
    "print(\"ğŸ”§ Processando dados...\")\n",
    "processed_data = analyzer.preprocess_data()\n",
    "print(f\"âœ… Dados processados: {processed_data.shape}\")\n",
    "\n",
    "print(\"ğŸ“ˆ Realizando anÃ¡lise estatÃ­stica...\")\n",
    "results = analyzer.perform_statistical_analysis()\n",
    "print(\"âœ… AnÃ¡lise estatÃ­stica concluÃ­da\")\n",
    "\n",
    "print(\"ğŸ‘¥ Executando anÃ¡lise de clusters...\")\n",
    "clusters = analyzer.clustering_analysis()\n",
    "print(\"âœ… AnÃ¡lise de clusters concluÃ­da\")\n",
    "\n",
    "print(\"â° Realizando anÃ¡lise de sÃ©ries temporais...\")\n",
    "time_series = analyzer.time_series_analysis()\n",
    "print(\"âœ… AnÃ¡lise temporal concluÃ­da\")\n",
    "\n",
    "print(\"ğŸ¨ Gerando visualizaÃ§Ãµes...\")\n",
    "analyzer.create_visualizations()\n",
    "print(\"âœ… VisualizaÃ§Ãµes salvas\")\n",
    "\n",
    "print(\"ğŸ“‹ Gerando relatÃ³rio final...\")\n",
    "report = analyzer.generate_report()\n",
    "print(\"âœ… RelatÃ³rio gerado\")\n",
    "\n",
    "# %%\n",
    "# ==================== RESULTADOS E INSIGHTS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š RESULTADOS PRINCIPAIS DA ANÃLISE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CorrelaÃ§Ã£o educaÃ§Ã£o-PIB\n",
    "corr_edu_gdp = report['correlation_summary']['education_gdp']\n",
    "print(f\"ğŸ“ˆ CorrelaÃ§Ã£o EducaÃ§Ã£o-PIB: {corr_edu_gdp:.3f}\")\n",
    "\n",
    "# Resultados da regressÃ£o\n",
    "rsquared = report['regression_results']['rsquared']\n",
    "edu_coef = report['regression_results']['params']['SE.SEC.ENRR']\n",
    "edu_pvalue = report['regression_results']['pvalues']['SE.SEC.ENRR']\n",
    "\n",
    "print(f\"ğŸ” RÂ² do modelo: {rsquared:.3f}\")\n",
    "print(f\"ğŸ“š Coeficiente EducaÃ§Ã£o: {edu_coef:.3f} (p-value: {edu_pvalue:.4f})\")\n",
    "\n",
    "# AnÃ¡lise de clusters\n",
    "if 'clustering_summary' in report:\n",
    "    print(f\"ğŸ‘¥ PaÃ­ses agrupados em {report['clustering_summary']['n_clusters']} clusters\")\n",
    "    for cluster, count in report['clustering_summary']['cluster_sizes'].items():\n",
    "        print(f\"   Cluster {cluster}: {count} paÃ­ses\")\n",
    "\n",
    "# AnÃ¡lise por paÃ­s\n",
    "print(\"\\nğŸ‡§ğŸ‡· AnÃ¡lise especÃ­fica do Brasil:\")\n",
    "brazil_data = analyzer.processed_data[analyzer.processed_data['country'] == 'BRA'].dropna()\n",
    "if not brazil_data.empty:\n",
    "    latest_year = brazil_data['year'].max()\n",
    "    latest_data = brazil_data[brazil_data['year'] == latest_year].iloc[0]\n",
    "    \n",
    "    print(f\"   Ano mais recente: {int(latest_year)}\")\n",
    "    print(f\"   PIB per capita: USD {float(latest_data['NY.GDP.PCAP.CD']):,.0f}\")\n",
    "    print(f\"   MatrÃ­cula secundÃ¡ria: {float(latest_data['SE.SEC.ENRR']):.1f}%\")\n",
    "    print(f\"   Gasto em educaÃ§Ã£o: {float(latest_data['SE.XPD.TOTL.GD.ZS']):.1f}% do PIB\")\n",
    "\n",
    "# %%\n",
    "# ==================== ANÃLISE COMPARATIVA ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸŒ ANÃLISE COMPARATIVA ENTRE PAÃSES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Primeiro, vamos verificar quais colunas estÃ£o disponÃ­veis\n",
    "print(\"Colunas disponÃ­veis no processed_data:\")\n",
    "print(analyzer.processed_data.columns.tolist())\n",
    "\n",
    "# Dados mais recentes por paÃ­s - usando os nomes corretos das colunas\n",
    "latest_data = []\n",
    "for country in analyzer.countries:\n",
    "    country_data = analyzer.processed_data[analyzer.processed_data['country'] == country].dropna()\n",
    "    if not country_data.empty:\n",
    "        latest_year = country_data['year'].max()\n",
    "        latest_row = country_data[country_data['year'] == latest_year].iloc[0]\n",
    "        \n",
    "        # Usar os nomes corretos das colunas do World Bank\n",
    "        latest_data.append({\n",
    "            'country': country,\n",
    "            'year': int(latest_year),\n",
    "            'NY.GDP.PCAP.CD': float(latest_row['NY.GDP.PCAP.CD']) if 'NY.GDP.PCAP.CD' in latest_row else None,\n",
    "            'SE.SEC.ENRR': float(latest_row['SE.SEC.ENRR']) if 'SE.SEC.ENRR' in latest_row else None,\n",
    "            'SE.XPD.TOTL.GD.ZS': float(latest_row['SE.XPD.TOTL.GD.ZS']) if 'SE.XPD.TOTL.GD.ZS' in latest_row else None\n",
    "        })\n",
    "\n",
    "latest_df = pd.DataFrame(latest_data)\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "latest_df = latest_df.dropna()\n",
    "\n",
    "# Top paÃ­ses em diferentes mÃ©tricas - usando os nomes corretos das colunas\n",
    "if not latest_df.empty and 'NY.GDP.PCAP.CD' in latest_df.columns:\n",
    "    print(\"\\nğŸ† Top 5 paÃ­ses por PIB per capita:\")\n",
    "    top_gdp = latest_df.nlargest(5, 'NY.GDP.PCAP.CD')[['country', 'NY.GDP.PCAP.CD']].copy()\n",
    "    top_gdp['NY.GDP.PCAP.CD'] = top_gdp['NY.GDP.PCAP.CD'].apply(lambda x: f\"USD {x:,.0f}\")\n",
    "    print(top_gdp.to_string(index=False))\n",
    "\n",
    "if not latest_df.empty and 'SE.SEC.ENRR' in latest_df.columns:\n",
    "    print(\"\\nğŸ“ Top 5 paÃ­ses por matrÃ­cula secundÃ¡ria:\")\n",
    "    top_edu = latest_df.nlargest(5, 'SE.SEC.ENRR')[['country', 'SE.SEC.ENRR']].copy()\n",
    "    top_edu['SE.SEC.ENRR'] = top_edu['SE.SEC.ENRR'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    print(top_edu.to_string(index=False))\n",
    "\n",
    "if not latest_df.empty and 'SE.XPD.TOTL.GD.ZS' in latest_df.columns:\n",
    "    print(\"\\nğŸ’° Top 5 paÃ­ses por gasto em educaÃ§Ã£o (% PIB):\")\n",
    "    top_spend = latest_df.nlargest(5, 'SE.XPD.TOTL.GD.ZS')[['country', 'SE.XPD.TOTL.GD.ZS']].copy()\n",
    "    top_spend['SE.XPD.TOTL.GD.ZS'] = top_spend['SE.XPD.TOTL.GD.ZS'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    print(top_spend.to_string(index=False))\n",
    "\n",
    "# %%\n",
    "# ==================== TESTES ESTATÃSTICOS AVANÃ‡ADOS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š TESTES ESTATÃSTICOS AVANÃ‡ADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se temos dados suficientes para anÃ¡lise\n",
    "if not latest_df.empty and 'NY.GDP.PCAP.CD' in latest_df.columns and 'SE.SEC.ENRR' in latest_df.columns:\n",
    "    \n",
    "    # Teste de diferenÃ§as entre grupos de renda\n",
    "    # Classificar paÃ­ses por renda\n",
    "    latest_df['income_group'] = pd.qcut(latest_df['NY.GDP.PCAP.CD'], 3, labels=['Baixa', 'MÃ©dia', 'Alta'])\n",
    "    \n",
    "    # ANOVA para diferenÃ§as na matrÃ­cula entre grupos de renda\n",
    "    groups = []\n",
    "    for group in ['Baixa', 'MÃ©dia', 'Alta']:\n",
    "        group_data = latest_df[latest_df['income_group'] == group]['SE.SEC.ENRR'].dropna()\n",
    "        if len(group_data) > 0:\n",
    "            groups.append(group_data)\n",
    "    \n",
    "    if len(groups) >= 2:\n",
    "        f_stat, p_value = stats.f_oneway(*groups)\n",
    "        print(f\"ğŸ“Š ANOVA - DiferenÃ§as na matrÃ­cula por grupo de renda:\")\n",
    "        print(f\"   F-statistic: {f_stat:.3f}, p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # CorrelaÃ§Ã£o e teste de significÃ¢ncia\n",
    "    corr_test = stats.pearsonr(latest_df['SE.SEC.ENRR'], latest_df['NY.GDP.PCAP.CD'])\n",
    "    print(f\"ğŸ” CorrelaÃ§Ã£o EducaÃ§Ã£o-PIB: {corr_test.statistic:.3f}\")\n",
    "    print(f\"ğŸ“‹ Teste de significÃ¢ncia da correlaÃ§Ã£o:\")\n",
    "    print(f\"   p-value: {corr_test.pvalue:.4f}\")\n",
    "    \n",
    "    # CorrelaÃ§Ã£o parcial (controlando por gastos em educaÃ§Ã£o)\n",
    "    if 'SE.XPD.TOTL.GD.ZS' in latest_df.columns:\n",
    "        # Usar regressÃ£o linear para correlaÃ§Ã£o parcial\n",
    "        X = latest_df[['SE.SEC.ENRR', 'SE.XPD.TOTL.GD.ZS']].dropna()\n",
    "        y = latest_df['NY.GDP.PCAP.CD'].loc[X.index]\n",
    "        \n",
    "        if len(X) > 5:\n",
    "            X = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            partial_corr = model.params['SE.SEC.ENRR']\n",
    "            print(f\"ğŸ“ˆ Coeficiente parcial EducaÃ§Ã£o-PIB (controlando gastos): {partial_corr:.3f}\")\n",
    "\n",
    "# %%\n",
    "# ==================== SALVANDO RESULTADOS COMPLETOS ====================\n",
    "\n",
    "# Salvar dados processados\n",
    "analyzer.processed_data.to_csv('processed_education_economic_data.csv', index=False)\n",
    "\n",
    "# Salvar resultados estatÃ­sticos detalhados\n",
    "statistical_results = {\n",
    "    'correlation_matrix': analyzer.results['correlation_matrix'].to_dict(),\n",
    "    'regression_summary': {\n",
    "        'rsquared': float(analyzer.results['regression_model'].rsquared),\n",
    "        'rsquared_adj': float(analyzer.results['regression_model'].rsquared_adj),\n",
    "        'f_statistic': float(analyzer.results['regression_model'].fvalue),\n",
    "        'f_pvalue': float(analyzer.results['regression_model'].f_pvalue),\n",
    "        'params': {k: float(v) for k, v in analyzer.results['regression_model'].params.items()},\n",
    "        'pvalues': {k: float(v) for k, v in analyzer.results['regression_model'].pvalues.items()}\n",
    "    },\n",
    "    'country_correlations': {k: float(v) for k, v in analyzer.results['country_correlations'].items()}\n",
    "}\n",
    "\n",
    "with open('statistical_results.json', 'w') as f:\n",
    "    json.dump(statistical_results, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lise completa concluÃ­da!\")\n",
    "print(\"ğŸ“ Arquivos salvos:\")\n",
    "print(\"   - processed_education_economic_data.csv\")\n",
    "print(\"   - statistical_results.json\")\n",
    "print(\"   - analysis_report.json\")\n",
    "print(\"   - complete_analysis.png\")\n",
    "\n",
    "# %%\n",
    "# ==================== INSIGHTS FINAIS ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¡ INSIGHTS E RECOMENDAÃ‡Ã•ES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Insights baseados nos resultados\n",
    "if corr_edu_gdp > 0.5:\n",
    "    print(\"ğŸ¯ Insight 1: Forte correlaÃ§Ã£o positiva entre educaÃ§Ã£o e crescimento econÃ´mico\")\n",
    "    print(\"   â†’ Investimentos em educaÃ§Ã£o tÃªm impacto significativo no PIB\")\n",
    "elif corr_edu_gdp > 0.3:\n",
    "    print(\"ğŸ¯ Insight 1: CorrelaÃ§Ã£o moderada entre educaÃ§Ã£o e crescimento econÃ´mico\")\n",
    "    print(\"   â†’ EducaÃ§Ã£o Ã© um dos fatores importantes para o desenvolvimento\")\n",
    "else:\n",
    "    print(\"ğŸ¯ Insight 1: CorrelaÃ§Ã£o fraca entre educaÃ§Ã£o e crescimento econÃ´mico\")\n",
    "    print(\"   â†’ Outros fatores podem ter maior impacto no crescimento\")\n",
    "\n",
    "if edu_pvalue < 0.05:\n",
    "    print(\"ğŸ¯ Insight 2: RelaÃ§Ã£o estatisticamente significativa (p < 0.05)\")\n",
    "    print(\"   â†’ Os resultados nÃ£o sÃ£o devidos ao acaso\")\n",
    "else:\n",
    "    print(\"ğŸ¯ Insight 2: RelaÃ§Ã£o nÃ£o estatisticamente significativa\")\n",
    "    print(\"   â†’ Resultados podem ser devido a variaÃ§Ã£o aleatÃ³ria\")\n",
    "\n",
    "# RecomendaÃ§Ãµes baseadas nos clusters\n",
    "if 'clustering_summary' in report:\n",
    "    cluster_sizes = report['clustering_summary']['cluster_sizes']\n",
    "    if len(cluster_sizes) > 1:\n",
    "        print(\"ğŸ¯ Insight 3: PaÃ­ses se agrupam em perfis distintos de desenvolvimento\")\n",
    "        print(\"   â†’ PolÃ­ticas educacionais devem ser adaptadas a cada perfil\")\n",
    "\n",
    "print(\"\\nğŸ“‹ RecomendaÃ§Ãµes para polÃ­ticas pÃºblicas:\")\n",
    "print(\"   1. Aumentar investimentos em educaÃ§Ã£o secundÃ¡ria e terciÃ¡ria\")\n",
    "print(\"   2. Focar na qualidade do ensino alÃ©m da quantidade de matrÃ­culas\")\n",
    "print(\"   3. Desenvolver polÃ­ticas especÃ­ficas para cada grupo de paÃ­ses\")\n",
    "print(\"   4. Monitorar continuamente a relaÃ§Ã£o educaÃ§Ã£o-crescimento\")\n",
    "\n",
    "print(\"\\nğŸ”® PrÃ³ximos passos para pesquisa:\")\n",
    "print(\"   1. Investigar causalidade (educaÃ§Ã£o â†’ crescimento ou crescimento â†’ educaÃ§Ã£o?)\")\n",
    "print(\"   2. Analisar o papel de variÃ¡veis intermediÃ¡rias (tecnologia, inovaÃ§Ã£o)\")\n",
    "print(\"   3. Estudo longitudinal de paÃ­ses especÃ­ficos\")\n",
    "print(\"   4. AnÃ¡lise de polÃ­ticas educacionais bem-sucedidas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
